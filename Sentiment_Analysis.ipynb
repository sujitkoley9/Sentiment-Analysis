{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sujitkoley9/Sentiment-Analysis/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKt9nTjgFWI0"
   },
   "source": [
    "<h1> <center>Sentiment Analysis </center> </h1>\n",
    "<b>Useful link: </b>\n",
    "\n",
    "\n",
    "1. https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\n",
    "2. https://realpython.com/python-keras-text-classification/\n",
    "\n",
    "3. https://medium.com/jatana/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f\n",
    "\n",
    "4. https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N5Mbzt71IuXF"
   },
   "source": [
    "# 1. **Importing packages**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKuhkGf7DkUo"
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta,datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "import gensim\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.summarization import keywords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout,Flatten\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nV2ftSn9K0lJ"
   },
   "source": [
    "# 2 . **Reading required files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFCqPWO0LASj"
   },
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('amazon_cells_labelled.txt', names=['review', 'sentiment'],sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBTvNGDOXH1Z"
   },
   "source": [
    "# 1. **Logistic Regression**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "1qXqwQG0XPcQ",
    "outputId": "ffe38e8b-d914-4cc5-f096-e6e8a5ac74a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit koley\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the text\n",
    "X = movie_df['review']\n",
    "y = movie_df['sentiment']\n",
    "\n",
    "\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "#  fit the vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df =1.0,min_df=1,analyzer='word')\n",
    "fit_obj = vectorizer.fit(X_train)\n",
    "\n",
    "# Transform the vectorizer\n",
    "X_train = fit_obj.transform(X_train)\n",
    "X_test = fit_obj.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mf-ho4rDbEJe"
   },
   "source": [
    "# 2. **Neural network without word embedding**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "j3flw2gzbLsr",
    "outputId": "b10fb79d-be8f-46cf-967a-cd8e36fc400e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                15470     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 15,481\n",
      "Trainable params: 15,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the text\n",
    "X = movie_df['review']\n",
    "y = movie_df['sentiment']\n",
    "\n",
    "\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "#  fit the vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df =1.0,min_df=1,analyzer='word')\n",
    "fit_obj = vectorizer.fit(X_train)\n",
    "\n",
    "# Transform the vectorizer\n",
    "X_train = fit_obj.transform(X_train)\n",
    "X_test = fit_obj.transform(X_test)\n",
    "\n",
    "# Neural Network \n",
    "classifier  = Sequential()\n",
    "classifier.add(Dense(10,input_shape=(X_train.shape[1],), activation = 'relu'))\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# model summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eXMAEjcddfQL",
    "outputId": "65dcbd52-8c7b-4d1a-e49a-69846bc13bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 0s 336us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5080\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 25us/sample - loss: 0.6903 - accuracy: 0.5547 - val_loss: 0.6917 - val_accuracy: 0.5240\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.6888 - accuracy: 0.5813 - val_loss: 0.6911 - val_accuracy: 0.5280\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.6873 - accuracy: 0.6213 - val_loss: 0.6904 - val_accuracy: 0.5360\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 0.6858 - accuracy: 0.6467 - val_loss: 0.6897 - val_accuracy: 0.5520\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.6842 - accuracy: 0.6800 - val_loss: 0.6890 - val_accuracy: 0.5720\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.6826 - accuracy: 0.6933 - val_loss: 0.6883 - val_accuracy: 0.5800\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.6809 - accuracy: 0.7267 - val_loss: 0.6876 - val_accuracy: 0.5960\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6792 - accuracy: 0.7560 - val_loss: 0.6868 - val_accuracy: 0.6160\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6775 - accuracy: 0.7653 - val_loss: 0.6861 - val_accuracy: 0.6200\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.6757 - accuracy: 0.7933 - val_loss: 0.6853 - val_accuracy: 0.6280\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.6739 - accuracy: 0.8107 - val_loss: 0.6845 - val_accuracy: 0.6400\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6720 - accuracy: 0.8227 - val_loss: 0.6836 - val_accuracy: 0.6440\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 0.6701 - accuracy: 0.8453 - val_loss: 0.6827 - val_accuracy: 0.6520\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.6682 - accuracy: 0.8587 - val_loss: 0.6818 - val_accuracy: 0.6600\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 0.6662 - accuracy: 0.8773 - val_loss: 0.6809 - val_accuracy: 0.6600\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6642 - accuracy: 0.8813 - val_loss: 0.6800 - val_accuracy: 0.6680\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 35us/sample - loss: 0.6621 - accuracy: 0.8893 - val_loss: 0.6790 - val_accuracy: 0.6720\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 35us/sample - loss: 0.6600 - accuracy: 0.8933 - val_loss: 0.6781 - val_accuracy: 0.6800\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6579 - accuracy: 0.9013 - val_loss: 0.6771 - val_accuracy: 0.6800\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.6557 - accuracy: 0.9053 - val_loss: 0.6761 - val_accuracy: 0.6800\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6535 - accuracy: 0.9080 - val_loss: 0.6752 - val_accuracy: 0.6800\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.6512 - accuracy: 0.9147 - val_loss: 0.6742 - val_accuracy: 0.6800\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.6489 - accuracy: 0.9187 - val_loss: 0.6732 - val_accuracy: 0.6880\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 0.6466 - accuracy: 0.9227 - val_loss: 0.6722 - val_accuracy: 0.6880\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.6442 - accuracy: 0.9253 - val_loss: 0.6712 - val_accuracy: 0.6920\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6418 - accuracy: 0.9293 - val_loss: 0.6702 - val_accuracy: 0.6920\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 35us/sample - loss: 0.6394 - accuracy: 0.9347 - val_loss: 0.6692 - val_accuracy: 0.6960\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6370 - accuracy: 0.9373 - val_loss: 0.6682 - val_accuracy: 0.6960\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.6345 - accuracy: 0.9413 - val_loss: 0.6672 - val_accuracy: 0.7040\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.6320 - accuracy: 0.9440 - val_loss: 0.6662 - val_accuracy: 0.7040\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.6295 - accuracy: 0.9467 - val_loss: 0.6652 - val_accuracy: 0.7080\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.6269 - accuracy: 0.9480 - val_loss: 0.6641 - val_accuracy: 0.7160\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 36us/sample - loss: 0.6244 - accuracy: 0.9480 - val_loss: 0.6631 - val_accuracy: 0.7120\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.6218 - accuracy: 0.9507 - val_loss: 0.6621 - val_accuracy: 0.7120\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.6192 - accuracy: 0.9507 - val_loss: 0.6610 - val_accuracy: 0.7160\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 36us/sample - loss: 0.6166 - accuracy: 0.9507 - val_loss: 0.6600 - val_accuracy: 0.7120\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.6139 - accuracy: 0.9507 - val_loss: 0.6590 - val_accuracy: 0.7120\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 0.6113 - accuracy: 0.9493 - val_loss: 0.6579 - val_accuracy: 0.7120\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 0.6086 - accuracy: 0.9493 - val_loss: 0.6569 - val_accuracy: 0.7120\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 43us/sample - loss: 0.6059 - accuracy: 0.9493 - val_loss: 0.6558 - val_accuracy: 0.7160\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.6032 - accuracy: 0.9493 - val_loss: 0.6548 - val_accuracy: 0.7160\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 0.6005 - accuracy: 0.9507 - val_loss: 0.6537 - val_accuracy: 0.7160\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 0.5978 - accuracy: 0.9507 - val_loss: 0.6527 - val_accuracy: 0.7160\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 35us/sample - loss: 0.5951 - accuracy: 0.9507 - val_loss: 0.6516 - val_accuracy: 0.7160\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.5923 - accuracy: 0.9507 - val_loss: 0.6505 - val_accuracy: 0.7160\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 0.5896 - accuracy: 0.9507 - val_loss: 0.6495 - val_accuracy: 0.7160\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.5868 - accuracy: 0.9520 - val_loss: 0.6484 - val_accuracy: 0.7160\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 0.5841 - accuracy: 0.9520 - val_loss: 0.6474 - val_accuracy: 0.7200\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 0.5813 - accuracy: 0.9520 - val_loss: 0.6463 - val_accuracy: 0.7120\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 35us/sample - loss: 0.5786 - accuracy: 0.9520 - val_loss: 0.6453 - val_accuracy: 0.7120\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 0.5758 - accuracy: 0.9547 - val_loss: 0.6442 - val_accuracy: 0.7080\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 0.5730 - accuracy: 0.9560 - val_loss: 0.6432 - val_accuracy: 0.7080\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.5702 - accuracy: 0.9573 - val_loss: 0.6422 - val_accuracy: 0.7160\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.5675 - accuracy: 0.9587 - val_loss: 0.6411 - val_accuracy: 0.7160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.5647 - accuracy: 0.9587 - val_loss: 0.6401 - val_accuracy: 0.7160\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.5619 - accuracy: 0.9587 - val_loss: 0.6390 - val_accuracy: 0.7160\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 25us/sample - loss: 0.5591 - accuracy: 0.9600 - val_loss: 0.6380 - val_accuracy: 0.7160\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 39us/sample - loss: 0.5563 - accuracy: 0.9600 - val_loss: 0.6369 - val_accuracy: 0.7160\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.5535 - accuracy: 0.9600 - val_loss: 0.6359 - val_accuracy: 0.7160\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.5507 - accuracy: 0.9600 - val_loss: 0.6348 - val_accuracy: 0.7200\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.5479 - accuracy: 0.9613 - val_loss: 0.6338 - val_accuracy: 0.7200\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.5451 - accuracy: 0.9613 - val_loss: 0.6327 - val_accuracy: 0.7200\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.5423 - accuracy: 0.9613 - val_loss: 0.6317 - val_accuracy: 0.7200\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.5395 - accuracy: 0.9613 - val_loss: 0.6306 - val_accuracy: 0.7200\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.5367 - accuracy: 0.9640 - val_loss: 0.6296 - val_accuracy: 0.7240\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.5339 - accuracy: 0.9640 - val_loss: 0.6286 - val_accuracy: 0.7240\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.5311 - accuracy: 0.9667 - val_loss: 0.6275 - val_accuracy: 0.7200\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.5283 - accuracy: 0.9680 - val_loss: 0.6265 - val_accuracy: 0.7200\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.5255 - accuracy: 0.9693 - val_loss: 0.6255 - val_accuracy: 0.7200\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.5227 - accuracy: 0.9707 - val_loss: 0.6245 - val_accuracy: 0.7200\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.5199 - accuracy: 0.9707 - val_loss: 0.6235 - val_accuracy: 0.7200\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.5171 - accuracy: 0.9707 - val_loss: 0.6225 - val_accuracy: 0.7200\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 36us/sample - loss: 0.5144 - accuracy: 0.9733 - val_loss: 0.6215 - val_accuracy: 0.7200\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.5116 - accuracy: 0.9733 - val_loss: 0.6204 - val_accuracy: 0.7200\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 36us/sample - loss: 0.5088 - accuracy: 0.9733 - val_loss: 0.6194 - val_accuracy: 0.7160\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.5060 - accuracy: 0.9720 - val_loss: 0.6184 - val_accuracy: 0.7160\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 35us/sample - loss: 0.5033 - accuracy: 0.9733 - val_loss: 0.6174 - val_accuracy: 0.7160\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 37us/sample - loss: 0.5005 - accuracy: 0.9747 - val_loss: 0.6164 - val_accuracy: 0.7160\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 27us/sample - loss: 0.4977 - accuracy: 0.9747 - val_loss: 0.6154 - val_accuracy: 0.7160\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.4950 - accuracy: 0.9747 - val_loss: 0.6144 - val_accuracy: 0.7120\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.4922 - accuracy: 0.9747 - val_loss: 0.6134 - val_accuracy: 0.7120\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.4895 - accuracy: 0.9747 - val_loss: 0.6125 - val_accuracy: 0.7120\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.4867 - accuracy: 0.9747 - val_loss: 0.6115 - val_accuracy: 0.7160\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 27us/sample - loss: 0.4840 - accuracy: 0.9747 - val_loss: 0.6105 - val_accuracy: 0.7160\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.4813 - accuracy: 0.9747 - val_loss: 0.6095 - val_accuracy: 0.7160\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.4785 - accuracy: 0.9760 - val_loss: 0.6086 - val_accuracy: 0.7160\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 27us/sample - loss: 0.4758 - accuracy: 0.9773 - val_loss: 0.6076 - val_accuracy: 0.7160\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 27us/sample - loss: 0.4731 - accuracy: 0.9773 - val_loss: 0.6066 - val_accuracy: 0.7160\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 32us/sample - loss: 0.4704 - accuracy: 0.9773 - val_loss: 0.6057 - val_accuracy: 0.7200\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 29us/sample - loss: 0.4677 - accuracy: 0.9787 - val_loss: 0.6047 - val_accuracy: 0.7200\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 0.4650 - accuracy: 0.9800 - val_loss: 0.6038 - val_accuracy: 0.7200\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.4623 - accuracy: 0.9800 - val_loss: 0.6028 - val_accuracy: 0.7200\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 31us/sample - loss: 0.4596 - accuracy: 0.9800 - val_loss: 0.6019 - val_accuracy: 0.7200\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 33us/sample - loss: 0.4569 - accuracy: 0.9813 - val_loss: 0.6009 - val_accuracy: 0.7160\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 28us/sample - loss: 0.4542 - accuracy: 0.9827 - val_loss: 0.6000 - val_accuracy: 0.7160\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 0.4516 - accuracy: 0.9827 - val_loss: 0.5991 - val_accuracy: 0.7200\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 40us/sample - loss: 0.4489 - accuracy: 0.9840 - val_loss: 0.5982 - val_accuracy: 0.7200\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 41us/sample - loss: 0.4463 - accuracy: 0.9840 - val_loss: 0.5972 - val_accuracy: 0.7200\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 35us/sample - loss: 0.4436 - accuracy: 0.9840 - val_loss: 0.5963 - val_accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "classifier.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = classifier.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    verbose=1 ,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "7YYSkKcRgEul",
    "outputId": "e8b0115f-bda6-4a9c-b8e1-a2e68f08423a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2L-d2CAjFcv"
   },
   "source": [
    "# 3. **Neural network with word embedding**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKEyMwnjgoKK"
   },
   "source": [
    "## 3.1 **LSTM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxhbeNgy-FKg"
   },
   "outputs": [],
   "source": [
    "# Cleaning the text\n",
    "X = movie_df['review']\n",
    "y = movie_df['sentiment']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "# fit method\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(X_train) \n",
    "\n",
    "# pad sequences\n",
    "max_length = max([len(s.split()) for s in X_train])\n",
    "\n",
    "# define vocabulary size\n",
    "vocab_size = len(tokenizer_obj.word_index) + 1 # Adding 1 because of reserved 0 index , 0 index stored padding\n",
    "\n",
    "\n",
    "# Transform\n",
    "X_train_tokens =  tokenizer_obj.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test)\n",
    "\n",
    "# Padding\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "wyd_H6a_bae9",
    "outputId": "3bf8eb74-b571-438a-b5b1-5a226c295acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 100)           157400    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 238,821\n",
      "Trainable params: 238,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "embedding_dim =100\n",
    "classifier  = Sequential()\n",
    "classifier.add(Embedding(input_dim=vocab_size, \n",
    "                         output_dim=embedding_dim, \n",
    "                         input_length=max_length))\n",
    "\n",
    "classifier.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "classifier.add(Dense(10, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# model summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "op2hs9pvcvjv",
    "outputId": "baa13c4a-4cf5-4d07-b4c8-c14277749710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 5s 7ms/sample - loss: 0.6938 - accuracy: 0.4733 - val_loss: 0.6933 - val_accuracy: 0.4960\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 1s 993us/sample - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 1s 964us/sample - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5120\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 1s 996us/sample - loss: 0.6926 - accuracy: 0.5427 - val_loss: 0.6931 - val_accuracy: 0.5080\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 1s 969us/sample - loss: 0.6930 - accuracy: 0.4893 - val_loss: 0.6931 - val_accuracy: 0.4960\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 1s 955us/sample - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.4960\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.6918 - accuracy: 0.5427 - val_loss: 0.6928 - val_accuracy: 0.5280\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.6904 - accuracy: 0.5613 - val_loss: 0.6927 - val_accuracy: 0.5160\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 1s 961us/sample - loss: 0.6874 - accuracy: 0.5800 - val_loss: 0.6906 - val_accuracy: 0.5400\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 1s 967us/sample - loss: 0.6802 - accuracy: 0.6120 - val_loss: 0.6803 - val_accuracy: 0.5800\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.6420 - accuracy: 0.7040 - val_loss: 0.6367 - val_accuracy: 0.6320\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 1s 995us/sample - loss: 0.5298 - accuracy: 0.8000 - val_loss: 0.5427 - val_accuracy: 0.7280\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 1s 935us/sample - loss: 0.4116 - accuracy: 0.8387 - val_loss: 0.5894 - val_accuracy: 0.7560\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 1s 913us/sample - loss: 0.2830 - accuracy: 0.9080 - val_loss: 0.6895 - val_accuracy: 0.7520\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.2044 - accuracy: 0.9360 - val_loss: 0.7667 - val_accuracy: 0.7440\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 1s 964us/sample - loss: 0.1217 - accuracy: 0.9627 - val_loss: 0.7983 - val_accuracy: 0.7880\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 1s 985us/sample - loss: 0.1335 - accuracy: 0.9667 - val_loss: 0.7856 - val_accuracy: 0.7840\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 1s 931us/sample - loss: 0.0834 - accuracy: 0.9813 - val_loss: 0.7650 - val_accuracy: 0.7640\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 1s 949us/sample - loss: 0.0631 - accuracy: 0.9813 - val_loss: 0.6806 - val_accuracy: 0.7920\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 1s 939us/sample - loss: 0.0552 - accuracy: 0.9840 - val_loss: 0.7279 - val_accuracy: 0.7840\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 1s 945us/sample - loss: 0.0432 - accuracy: 0.9893 - val_loss: 0.9329 - val_accuracy: 0.7680\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 1s 937us/sample - loss: 0.0305 - accuracy: 0.9947 - val_loss: 1.0351 - val_accuracy: 0.7720\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0283 - accuracy: 0.9933 - val_loss: 1.1253 - val_accuracy: 0.7800\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 1s 915us/sample - loss: 0.0184 - accuracy: 0.9960 - val_loss: 1.1712 - val_accuracy: 0.7800\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 1s 965us/sample - loss: 0.0095 - accuracy: 0.9973 - val_loss: 1.1954 - val_accuracy: 0.7800\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0060 - accuracy: 0.9987 - val_loss: 1.2279 - val_accuracy: 0.7880\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2615 - val_accuracy: 0.7840\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0156 - accuracy: 0.9973 - val_loss: 1.0995 - val_accuracy: 0.7920\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.9918 - val_accuracy: 0.7800\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 1s 998us/sample - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.9260 - val_accuracy: 0.7840\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 1s 957us/sample - loss: 0.0100 - accuracy: 0.9987 - val_loss: 1.0167 - val_accuracy: 0.7800\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0115 - accuracy: 0.9987 - val_loss: 1.1595 - val_accuracy: 0.7920\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3177 - val_accuracy: 0.7880\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 9.7692e-04 - accuracy: 1.0000 - val_loss: 1.4323 - val_accuracy: 0.7680\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 7.7767e-04 - accuracy: 1.0000 - val_loss: 1.5153 - val_accuracy: 0.7680\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.5410 - val_accuracy: 0.7800\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.5382 - val_accuracy: 0.7840\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 1s 971us/sample - loss: 4.7513e-04 - accuracy: 1.0000 - val_loss: 1.5405 - val_accuracy: 0.7800\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 1s 966us/sample - loss: 4.2229e-04 - accuracy: 1.0000 - val_loss: 1.5433 - val_accuracy: 0.7800\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 1s 979us/sample - loss: 4.2047e-04 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.7720\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 1s 996us/sample - loss: 4.0653e-04 - accuracy: 1.0000 - val_loss: 1.6190 - val_accuracy: 0.7720\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 1s 964us/sample - loss: 3.7944e-04 - accuracy: 1.0000 - val_loss: 1.6400 - val_accuracy: 0.7720\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 1s 957us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 1.6164 - val_accuracy: 0.7800\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 1s 967us/sample - loss: 0.0017 - accuracy: 0.9987 - val_loss: 1.5953 - val_accuracy: 0.7920\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.4849 - val_accuracy: 0.7960\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 6.2026e-04 - accuracy: 1.0000 - val_loss: 1.4575 - val_accuracy: 0.7920\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 5.2443e-04 - accuracy: 1.0000 - val_loss: 1.4210 - val_accuracy: 0.7880\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.3980 - val_accuracy: 0.7880\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0043 - accuracy: 0.9973 - val_loss: 1.3930 - val_accuracy: 0.7880\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 4.0645e-04 - accuracy: 1.0000 - val_loss: 1.4052 - val_accuracy: 0.7920\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 5.6657e-04 - accuracy: 1.0000 - val_loss: 1.4030 - val_accuracy: 0.7960\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 7.6718e-04 - accuracy: 1.0000 - val_loss: 1.4116 - val_accuracy: 0.8080\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 6.8782e-04 - accuracy: 1.0000 - val_loss: 1.4322 - val_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.8080\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0116 - accuracy: 0.9987 - val_loss: 1.4709 - val_accuracy: 0.7960\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 1s 1ms/sample - loss: 4.2133e-04 - accuracy: 1.0000 - val_loss: 1.5049 - val_accuracy: 0.8000\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 5.5739e-04 - accuracy: 1.0000 - val_loss: 1.5276 - val_accuracy: 0.7960\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0018 - accuracy: 0.9987 - val_loss: 1.5299 - val_accuracy: 0.8040\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 1s 998us/sample - loss: 3.5248e-04 - accuracy: 1.0000 - val_loss: 1.5324 - val_accuracy: 0.8000\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 1s 996us/sample - loss: 0.0018 - accuracy: 0.9987 - val_loss: 1.5356 - val_accuracy: 0.7960\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 7.3018e-04 - accuracy: 1.0000 - val_loss: 1.5896 - val_accuracy: 0.7920\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5903 - val_accuracy: 0.7920\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 3.1516e-04 - accuracy: 1.0000 - val_loss: 1.6062 - val_accuracy: 0.7920\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 2.1978e-04 - accuracy: 1.0000 - val_loss: 1.6423 - val_accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 1.9988e-04 - accuracy: 1.0000 - val_loss: 1.6571 - val_accuracy: 0.7880\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 2.0412e-04 - accuracy: 1.0000 - val_loss: 1.6707 - val_accuracy: 0.7880\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 1s 980us/sample - loss: 1.7569e-04 - accuracy: 1.0000 - val_loss: 1.6812 - val_accuracy: 0.7880\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 1.8569e-04 - accuracy: 1.0000 - val_loss: 1.6874 - val_accuracy: 0.7880\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 1s 944us/sample - loss: 1.7073e-04 - accuracy: 1.0000 - val_loss: 1.6912 - val_accuracy: 0.7920\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 2.4719e-04 - accuracy: 1.0000 - val_loss: 1.6949 - val_accuracy: 0.7920\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 1s 935us/sample - loss: 5.4813e-04 - accuracy: 1.0000 - val_loss: 1.6770 - val_accuracy: 0.7960\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 1s 879us/sample - loss: 0.0017 - accuracy: 0.9987 - val_loss: 1.6836 - val_accuracy: 0.7960\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 1s 932us/sample - loss: 1.6615e-04 - accuracy: 1.0000 - val_loss: 1.7287 - val_accuracy: 0.7920\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 1s 896us/sample - loss: 1.5583e-04 - accuracy: 1.0000 - val_loss: 1.7340 - val_accuracy: 0.7920\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 1s 884us/sample - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.6898 - val_accuracy: 0.7880\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 1s 915us/sample - loss: 4.5714e-04 - accuracy: 1.0000 - val_loss: 1.6986 - val_accuracy: 0.7880\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 1s 947us/sample - loss: 0.0135 - accuracy: 0.9973 - val_loss: 1.6616 - val_accuracy: 0.7880\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 1s 944us/sample - loss: 0.0051 - accuracy: 0.9987 - val_loss: 1.5823 - val_accuracy: 0.8040\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 1s 904us/sample - loss: 5.3128e-04 - accuracy: 1.0000 - val_loss: 1.7677 - val_accuracy: 0.7640\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 1s 1000us/sample - loss: 0.0120 - accuracy: 0.9947 - val_loss: 1.7030 - val_accuracy: 0.7760\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 1s 893us/sample - loss: 1.8494e-04 - accuracy: 1.0000 - val_loss: 1.8102 - val_accuracy: 0.7680\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 1s 894us/sample - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.7573 - val_accuracy: 0.7680\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 1s 882us/sample - loss: 0.0146 - accuracy: 0.9960 - val_loss: 1.6296 - val_accuracy: 0.7920\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 1s 843us/sample - loss: 3.8255e-04 - accuracy: 1.0000 - val_loss: 1.6835 - val_accuracy: 0.7720\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 1s 871us/sample - loss: 0.0117 - accuracy: 0.9987 - val_loss: 1.7452 - val_accuracy: 0.7760\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 1s 786us/sample - loss: 0.0019 - accuracy: 0.9987 - val_loss: 1.6991 - val_accuracy: 0.7760\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 1s 854us/sample - loss: 4.4919e-04 - accuracy: 1.0000 - val_loss: 1.7173 - val_accuracy: 0.7640\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 1s 857us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7146 - val_accuracy: 0.7680\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 1s 843us/sample - loss: 3.9768e-04 - accuracy: 1.0000 - val_loss: 1.6346 - val_accuracy: 0.7760\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 1s 839us/sample - loss: 3.2260e-04 - accuracy: 1.0000 - val_loss: 1.6171 - val_accuracy: 0.7880\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 1s 844us/sample - loss: 2.8254e-04 - accuracy: 1.0000 - val_loss: 1.6087 - val_accuracy: 0.7880\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 1s 797us/sample - loss: 3.2702e-04 - accuracy: 1.0000 - val_loss: 1.6060 - val_accuracy: 0.7800\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 1s 867us/sample - loss: 4.2426e-04 - accuracy: 1.0000 - val_loss: 1.6028 - val_accuracy: 0.7800\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 1s 921us/sample - loss: 6.8536e-04 - accuracy: 1.0000 - val_loss: 1.6074 - val_accuracy: 0.7800\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 1s 870us/sample - loss: 2.6966e-04 - accuracy: 1.0000 - val_loss: 1.6161 - val_accuracy: 0.7800\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 1s 831us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6443 - val_accuracy: 0.7800\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 1s 903us/sample - loss: 2.2769e-04 - accuracy: 1.0000 - val_loss: 1.6937 - val_accuracy: 0.7840\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 1s 920us/sample - loss: 2.1903e-04 - accuracy: 1.0000 - val_loss: 1.7209 - val_accuracy: 0.7760\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 1s 871us/sample - loss: 3.5261e-04 - accuracy: 1.0000 - val_loss: 1.7368 - val_accuracy: 0.7760\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 1s 851us/sample - loss: 2.2292e-04 - accuracy: 1.0000 - val_loss: 1.7483 - val_accuracy: 0.7760\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "classifier.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = classifier.fit(X_train_pad, np.array(y_train),\n",
    "                    epochs=100,\n",
    "                    verbose=1 ,\n",
    "                    validation_data=(X_test_pad, np.array(y_test)),\n",
    "                    batch_size=X_test_pad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "GbTRlAPgcZ1Q",
    "outputId": "49951c1a-fe04-43de-d1cb-82462d935c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier.evaluate(X_test_pad, np.array(y_test), verbose=False)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybGbMXfBgyec"
   },
   "source": [
    "## 3.2 **GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "NtjqLqnEg8_C",
    "outputId": "19f89811-9a31-438e-87a9-234ba202edf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           157400    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 219,021\n",
      "Trainable params: 219,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "embedding_dim =100\n",
    "classifier  = Sequential()\n",
    "classifier.add(Embedding(input_dim=vocab_size, \n",
    "                         output_dim=embedding_dim, \n",
    "                         input_length=max_length))\n",
    "\n",
    "classifier.add(GRU(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "classifier.add(Dense(10, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "# model summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yHM5-c2ahAM6",
    "outputId": "57781ed4-ea3a-4f94-da56-bab4ff2dc666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 4s 6ms/sample - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 1s 835us/sample - loss: 0.6923 - accuracy: 0.5093 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 1s 877us/sample - loss: 0.6934 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 1s 901us/sample - loss: 0.6923 - accuracy: 0.5187 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 1s 775us/sample - loss: 0.6918 - accuracy: 0.5253 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 1s 825us/sample - loss: 0.6923 - accuracy: 0.5227 - val_loss: 0.6934 - val_accuracy: 0.4960\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 1s 811us/sample - loss: 0.6942 - accuracy: 0.5040 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 1s 883us/sample - loss: 0.6923 - accuracy: 0.5360 - val_loss: 0.6934 - val_accuracy: 0.5040\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 1s 881us/sample - loss: 0.6925 - accuracy: 0.5187 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 1s 908us/sample - loss: 0.6910 - accuracy: 0.5427 - val_loss: 0.6936 - val_accuracy: 0.4960\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 1s 844us/sample - loss: 0.6905 - accuracy: 0.5067 - val_loss: 0.6936 - val_accuracy: 0.4960\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 1s 925us/sample - loss: 0.6863 - accuracy: 0.5533 - val_loss: 0.6929 - val_accuracy: 0.5080\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 1s 861us/sample - loss: 0.6790 - accuracy: 0.6067 - val_loss: 0.6925 - val_accuracy: 0.5320\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 1s 852us/sample - loss: 0.6590 - accuracy: 0.6373 - val_loss: 0.6903 - val_accuracy: 0.5600\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 1s 863us/sample - loss: 0.5776 - accuracy: 0.7160 - val_loss: 0.6762 - val_accuracy: 0.5680\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 1s 851us/sample - loss: 0.4978 - accuracy: 0.7893 - val_loss: 0.6609 - val_accuracy: 0.5600\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 1s 879us/sample - loss: 0.3785 - accuracy: 0.8347 - val_loss: 0.6519 - val_accuracy: 0.6200\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 1s 858us/sample - loss: 0.3212 - accuracy: 0.8800 - val_loss: 0.6368 - val_accuracy: 0.6720\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 1s 829us/sample - loss: 0.2373 - accuracy: 0.9160 - val_loss: 0.6222 - val_accuracy: 0.6360\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 1s 836us/sample - loss: 0.1677 - accuracy: 0.9453 - val_loss: 0.5725 - val_accuracy: 0.7560\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 1s 843us/sample - loss: 0.1122 - accuracy: 0.9680 - val_loss: 0.5425 - val_accuracy: 0.7840\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 1s 784us/sample - loss: 0.0887 - accuracy: 0.9787 - val_loss: 0.5374 - val_accuracy: 0.7480\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 1s 808us/sample - loss: 0.0384 - accuracy: 0.9907 - val_loss: 0.5507 - val_accuracy: 0.7800\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 1s 800us/sample - loss: 0.0201 - accuracy: 0.9973 - val_loss: 0.5424 - val_accuracy: 0.7840\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 1s 784us/sample - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.5105 - val_accuracy: 0.7880\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 1s 832us/sample - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.4875 - val_accuracy: 0.7760\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 1s 808us/sample - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.5030 - val_accuracy: 0.7640\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 1s 964us/sample - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.4846 - val_accuracy: 0.7520\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0057 - accuracy: 0.9973 - val_loss: 0.4754 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.4864 - val_accuracy: 0.7800\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.4823 - val_accuracy: 0.7920\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.4632 - val_accuracy: 0.8040\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 1s 953us/sample - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.4661 - val_accuracy: 0.7840\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 1s 893us/sample - loss: 0.0020 - accuracy: 0.9987 - val_loss: 0.4693 - val_accuracy: 0.7760\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.4589 - val_accuracy: 0.7920\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 1s 853us/sample - loss: 3.2946e-04 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.7920\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 1s 859us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.8040\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 1s 833us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.8080\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 1s 869us/sample - loss: 5.1216e-04 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.8080\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 1s 857us/sample - loss: 3.5977e-04 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.8080\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 1s 885us/sample - loss: 5.4443e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.8080\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 1s 879us/sample - loss: 5.2184e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.8040\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 1s 963us/sample - loss: 8.3506e-04 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.7960\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 1s 871us/sample - loss: 4.5993e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.7960\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 1s 806us/sample - loss: 1.4174e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.7960\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 1s 833us/sample - loss: 9.0772e-05 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.7920\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 1s 804us/sample - loss: 2.5238e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.8040\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 1s 832us/sample - loss: 1.5611e-04 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.8040\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 1s 846us/sample - loss: 3.9872e-04 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8040\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 1s 795us/sample - loss: 1.7905e-04 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.8040\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 1s 832us/sample - loss: 5.1744e-05 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 1s 846us/sample - loss: 3.7347e-05 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 1s 909us/sample - loss: 7.9878e-05 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 1s 853us/sample - loss: 5.1115e-05 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.7960\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 1s 883us/sample - loss: 7.3385e-05 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.7960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "750/750 [==============================] - 1s 812us/sample - loss: 6.6101e-05 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.7960\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 1s 856us/sample - loss: 3.6549e-04 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 1s 861us/sample - loss: 4.0755e-05 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.8120\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 1s 805us/sample - loss: 3.1695e-05 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.8040\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 1s 839us/sample - loss: 3.4660e-05 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.8080\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 1s 799us/sample - loss: 4.4921e-05 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.8040\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 1s 812us/sample - loss: 4.3181e-04 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.8080\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 1s 845us/sample - loss: 1.7222e-04 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.8040\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 1s 791us/sample - loss: 1.6842e-05 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8120\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 1s 797us/sample - loss: 3.0228e-05 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8080\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 1s 823us/sample - loss: 5.2691e-05 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.8080\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 1s 833us/sample - loss: 8.9041e-06 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.8120\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 1s 840us/sample - loss: 1.3690e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8080\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 1s 807us/sample - loss: 0.0207 - accuracy: 0.9987 - val_loss: 0.4480 - val_accuracy: 0.8040\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 1s 807us/sample - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.4363 - val_accuracy: 0.8120\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 1s 999us/sample - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.4709 - val_accuracy: 0.7800\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 1s 853us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5432 - val_accuracy: 0.7080\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 1s 825us/sample - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.5436 - val_accuracy: 0.7400\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 1s 868us/sample - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.5283 - val_accuracy: 0.7800\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 1s 788us/sample - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.5322 - val_accuracy: 0.7480\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 1s 881us/sample - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.5098 - val_accuracy: 0.7600\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 1s 983us/sample - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.4735 - val_accuracy: 0.7720\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 1s 819us/sample - loss: 9.4047e-04 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.7680\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 1s 871us/sample - loss: 4.6013e-04 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.7640\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 1s 827us/sample - loss: 2.0211e-04 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.7640\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 1s 780us/sample - loss: 0.0157 - accuracy: 0.9973 - val_loss: 0.5021 - val_accuracy: 0.7720\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 1s 867us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.7720\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 1s 843us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.7640\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 1s 951us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5481 - val_accuracy: 0.6800\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5807 - val_accuracy: 0.6480\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0063 - accuracy: 0.9973 - val_loss: 0.5406 - val_accuracy: 0.7000\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 3.7574e-04 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.7640\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 1s 948us/sample - loss: 8.4834e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.7600\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 1s 893us/sample - loss: 2.0238e-04 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.7560\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 1s 917us/sample - loss: 8.4822e-04 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.7560\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 1s 915us/sample - loss: 1.9368e-04 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.7560\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 1.1002e-04 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.7640\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 1s 929us/sample - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.4738 - val_accuracy: 0.7600\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 1s 896us/sample - loss: 1.6646e-04 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 1s 779us/sample - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 1s 799us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.7640\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 1s 884us/sample - loss: 8.7885e-04 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.7320\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.5588 - val_accuracy: 0.6840\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 1s 891us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.6880\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 1s 807us/sample - loss: 5.6652e-04 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.7360\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "classifier.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = classifier.fit(X_train_pad, np.array(y_train),\n",
    "                    epochs=100,\n",
    "                    verbose=1 ,\n",
    "                    validation_data=(X_test_pad, np.array(y_test)),\n",
    "                    batch_size=X_test_pad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "py08NonLhDjq",
    "outputId": "84c0cc65-772e-41a9-8c09-7f2ffd69a91e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.736\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier.evaluate(X_test_pad, np.array(y_test), verbose=False)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7kupPNV5AZg"
   },
   "source": [
    "# 5. **Neural network with pretrained word embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9XmeUM47Z5f"
   },
   "source": [
    "**Creating word embedding matrix from pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1P4J0BC5I-s"
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('wiki-news-300d-1M.vec',\"rb\")):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "\n",
    "# create token-embedding mapping\n",
    "word_index = tokenizer_obj.word_index \n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qYvR6J8c-vgk"
   },
   "source": [
    "## 5.1 **LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cQnQoCu-bME"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'output_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a5ff7f8a3aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                          \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                          \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                          trainable=False))\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'output_dim'"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "embedding_dim =300\n",
    "classifier  = Sequential()\n",
    "classifier.add(Embedding(input_dim=vocab_size, \n",
    "                        # output_dim=embedding_dim,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length=max_length,\n",
    "                         trainable=False))\n",
    "\n",
    "classifier.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "classifier.add(Dense(10, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# model summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSdfv6OC-7Ls"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "classifier.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = classifier.fit(X_train_pad, np.array(y_train),\n",
    "                    epochs=100,\n",
    "                    verbose=1 ,\n",
    "                    validation_data=(X_test_pad, np.array(y_test)),\n",
    "                    batch_size=X_test_pad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0qqWz1K-80V"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.evaluate(X_test_pad, np.array(y_test), verbose=True)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rKxxofUP_F1A"
   },
   "source": [
    "## 5.2 **GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3ISENis_Ja2"
   },
   "outputs": [],
   "source": [
    "# GRU\n",
    "embedding_dim =100\n",
    "classifier  = Sequential()\n",
    "classifier.add(Embedding(input_dim=vocab_size, \n",
    "                         output_dim=embedding_dim,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length=max_length,\n",
    "                         trainable=False))\n",
    "\n",
    "classifier.add(GRU(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "classifier.add(Dense(10, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# model summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqRe33WA_JEN"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "classifier.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = classifier.fit(X_train_pad, np.array(y_train),\n",
    "                    epochs=100,\n",
    "                    verbose=1 ,\n",
    "                    validation_data=(X_test_pad, np.array(y_test)),\n",
    "                    batch_size=X_test_pad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0kHdqQL_Iyl"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.evaluate(X_test_pad, np.array(y_test), verbose=True)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiK7Qt9-5Kh3"
   },
   "source": [
    "#6. **Using context free word embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWhSAJME5Xzt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Sentiment-Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
